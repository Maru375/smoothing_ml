{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84806715",
   "metadata": {},
   "source": "> # 공통 환경 처리"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16400a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T00:55:43.420397Z",
     "start_time": "2024-04-24T00:55:41.140160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb_client in /home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages (1.41.0)\n",
      "Requirement already satisfied: reactivex>=4.0.4 in /home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages (from influxdb_client) (4.0.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages (from influxdb_client) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages (from influxdb_client) (2.8.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages (from influxdb_client) (68.2.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages (from influxdb_client) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages (from python-dateutil>=2.5.3->influxdb_client) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages (from reactivex>=4.0.4->influxdb_client) (4.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install influxdb_client"
   ]
  },
  {
   "cell_type": "code",
   "id": "46e54772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T06:47:04.413344Z",
     "start_time": "2024-04-24T06:47:04.094616Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from influxdb_client import InfluxDBClient\n",
    "from datetime import datetime, timedelta"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Influx DB 접속 정보 및 장치 위치 맵핑 정보",
   "id": "c6c3a3b4f5ea98a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# InfluxDB 설정 정보\n",
    "url = \"http://133.186.144.22:8086\"\n",
    "token = \"BPJ1pnKvoaov4Tte971t0zpRSTUXNZvrshU7u3UPheAIsBeUJEFfbKjfsZjtwZmugkHJEGRW17lH4bR9ybanNQ==\"\n",
    "org = \"smoothing\"\n",
    "\n",
    "# 디바이스 ID와 위치를 매핑\n",
    "location_mapping = {\n",
    "    '24e124126d152919': 'indoor',\n",
    "    '24e124126d152969': 'bottom_right_corner',\n",
    "    '24e124128c067999': 'indoor',\n",
    "    '24e124785c389818': 'bottom_left_corner',\n",
    "    '24e124785c421885': 'top_right_corner'\n",
    "}"
   ],
   "id": "f7fb2f9922864375"
  },
  {
   "cell_type": "markdown",
   "id": "7f08064d",
   "metadata": {},
   "source": "> # 데이터 집계 함수"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "influx DB에서 데이터를 받아와 Time, Value, Place, Location, Device 컬럼 형태로 지정을 하였다.\n",
    "\n",
    "또한 전력 데이터와 온도 데이터를 받을 예정이다."
   ],
   "id": "16c89731a4b83f08"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c508c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T00:55:45.855770Z",
     "start_time": "2024-04-24T00:55:45.793445Z"
    }
   },
   "outputs": [],
   "source": [
    "# InfluxDB 클라이언트 생성\n",
    "def create_client(url, token, org):\n",
    "    return InfluxDBClient(url=url, token=token, org=org)\n",
    "\n",
    "# 쿼리 실행 및 DataFrame으로 변환\n",
    "def query_to_dataframe(client, query):\n",
    "    result = client.query_api().query(query=query)\n",
    "    results = []\n",
    "    \n",
    "    for table in result:\n",
    "        for record in table.records:\n",
    "            results.append({\n",
    "                \"time\": record.get_time(),\n",
    "                \"value\": record.get_value(),\n",
    "                \"place\": record.values.get(\"place\"),\n",
    "                \"location\": record.values.get(\"location\"),\n",
    "                \"device\": record.values.get(\"device\")\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['time'] = df['time'].astype(str).str.replace(r'\\+00:00$', '', regex=True)\n",
    "    return df\n",
    "\n",
    "# 데이터를 날짜를 지정하여 CSV 파일로 저장\n",
    "def save_csv(df, file_pattern, directory):\n",
    "    # 경로가 존재하는지 확인하고, 없다면 생성\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    current_date = datetime.now()\n",
    "    previous_date = current_date - timedelta(days=1)\n",
    "    filename = f\"{directory}{previous_date.strftime(file_pattern)}\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "# 온도 Data에서 'device' 열에 따라 'location' 열을 업데이트    \n",
    "def update_location(df, location_mapping):\n",
    "    df['location'] = df['device'].map(location_mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e48ee",
   "metadata": {},
   "source": "### 각 데이터 조회 및 CSV변환 수행"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de06b4e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T00:55:59.695670Z",
     "start_time": "2024-04-24T00:55:58.388814Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time  value   place   location     device\n",
      "0  2024-04-23 00:02:00   26.0  office  a_project  gems-3500\n",
      "1  2024-04-23 00:04:00   25.0  office  a_project  gems-3500\n",
      "2  2024-04-23 00:06:00   26.0  office  a_project  gems-3500\n",
      "3  2024-04-23 00:08:00   25.0  office  a_project  gems-3500\n",
      "4  2024-04-23 00:10:00   26.0  office  a_project  gems-3500\n",
      "                  time  value   place location            device\n",
      "0  2024-04-23 00:02:00   23.6  office   indoor  24e124126d152919\n",
      "1  2024-04-23 00:04:00   23.5  office   indoor  24e124126d152919\n",
      "2  2024-04-23 00:06:00   23.6  office   indoor  24e124126d152919\n",
      "3  2024-04-23 00:08:00   23.6  office   indoor  24e124126d152919\n",
      "4  2024-04-23 00:10:00   23.6  office   indoor  24e124126d152919\n"
     ]
    }
   ],
   "source": [
    "# 클라이언트 생성 및 쿼리 실행\n",
    "client = create_client(url, token, org)\n",
    "\n",
    "# 전력 조회 Flux 쿼리\n",
    "query_powermetrics = '''\n",
    "import \"date\"\n",
    "\n",
    "from(bucket: \"powermetrics_data\")\n",
    "  |> range(start: date.sub(d: 1d, from: date.truncate(t: now(), unit: 1d)), stop: date.truncate(t: now(), unit: 1d))\n",
    "  |> filter(fn: (r) => r[\"phase\"] == \"total\")\n",
    "  |> filter(fn: (r) => r[\"description\"] == \"w\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\" or r[\"place\"] == \"office\")\n",
    "  |> filter(fn: (r) => r[\"location\"] != \"main\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# CSV 변환\n",
    "df_powermetrics = query_to_dataframe(client, query_powermetrics)\n",
    "print(df_powermetrics.head())\n",
    "save_csv(df_powermetrics, \"%m_%d_powermetrics_data.csv\", \"powermetrics/\")\n",
    "\n",
    "\n",
    "# 온도 조회 Flux 쿼리\n",
    "query_environmental = '''\n",
    "import \"date\"\n",
    "from(bucket: \"environmentalsensors_data\")\n",
    "  |> range(start: date.sub(d: 1d, from: date.truncate(t: now(), unit: 1d)), stop: date.truncate(t: now(), unit: 1d))\n",
    "  |> filter(fn: (r) => r[\"measurement\"] == \"temperature\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\" or r[\"place\"] == \"office\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# CSV 변환\n",
    "df_environmental = query_to_dataframe(client, query_environmental)\n",
    "df_environmental_fix = update_location(df_environmental, location_mapping)\n",
    "print(df_environmental_fix.head())\n",
    "save_csv(df_environmental_fix, \"%m_%d_environmentalsensors_data.csv\", \"environmentalsensors/\")\n",
    "\n",
    "# 클라이언트 종료\n",
    "client.close()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> # 데이터 전처리",
   "id": "8cb9999c8f3aa739"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "데이터 전처리를 위해 결측치 제거와 이상치 제거를 할 것이다.\n",
    "\n",
    "온도데이터와, 전력데이터 빈값이 있을 수 있으므로 결측치를 제거한다.\n",
    "\n",
    "이상치는 어떠한 것을 위해 제거한다."
   ],
   "id": "ef66dd972c0c777f"
  },
  {
   "cell_type": "markdown",
   "id": "acfcf9407e5143bc",
   "metadata": {},
   "source": "### 전체 데이터 병합 및 결측치 처리 함수"
  },
  {
   "cell_type": "code",
   "id": "b7f609080cfb5ae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T05:16:13.998971Z",
     "start_time": "2024-04-24T05:16:13.992224Z"
    }
   },
   "source": [
    "# 전체 데이터 병합\n",
    "def merge_and_compute_stats_by_time_and_place(directory_path, file_name):\n",
    "    # 디렉토리 내의 모든 CSV 파일 목록을 생성\n",
    "    csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "    # 모든 CSV 파일을 데이터 프레임으로 읽어와 하나로 병합\n",
    "    data_frames = []\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        # 'time' 컬럼을 datetime으로 변환\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        # 'time_hour_min' 컬럼을 생성하여 시간과 분만 추출\n",
    "        df['time_hour_min'] = df['time'].dt.strftime('%H:%M')\n",
    "        data_frames.append(df)\n",
    "\n",
    "    # 모든 데이터 프레임을 하나로 병합\n",
    "    merged_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # 'time', 'place', 'location' 별로 그룹화하고 각 통계치 계산\n",
    "    result_df = merged_df.groupby(['time_hour_min', 'place', 'location'])['value'].agg(\n",
    "        min_value='min',       # 최소값\n",
    "        max_value='max',       # 최대값\n",
    "        mean_value='mean',     # 평균\n",
    "        median_value='median', # 중앙값\n",
    "    ).reset_index()\n",
    "\n",
    "    # std_dev 컬럼에서 NaN 값 0으로 대체\n",
    "    result_df['std_dev'].fillna(0, inplace=True)\n",
    "\n",
    "    # 결과 데이터 프레임을 CSV 파일로 저장\n",
    "    result_df.to_csv(file_name, index=False)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# 결측치 확인 및 처리\n",
    "def load_and_clean_data(input_directory_path, output_directory_path):\n",
    "    summary = []\n",
    "\n",
    "    # 해당 디렉토리의 모든 파일을 리스트업\n",
    "    files = [f for f in os.listdir(input_directory_path) if f.endswith('.csv')]\n",
    "\n",
    "    for file in files:\n",
    "        file_summary = {\"file\": file}\n",
    "        input_file_path = os.path.join(input_directory_path, file)\n",
    "\n",
    "        # 데이터 불러오기\n",
    "        df = pd.read_csv(input_file_path)\n",
    "        initial_shape = df.shape\n",
    "\n",
    "        # 결측치 제거\n",
    "        missing_before = df.isnull().sum().sum()\n",
    "        df.dropna(inplace=True)\n",
    "        missing_after = df.isnull().sum().sum()\n",
    "\n",
    "        # 결과 요약\n",
    "        file_summary[\"initial_rows\"] = initial_shape[0]\n",
    "        file_summary[\"final_rows\"] = df.shape[0]\n",
    "        file_summary[\"missing_removed\"] = missing_before\n",
    "\n",
    "        # 수정된 데이터 저장\n",
    "        if not os.path.exists(output_directory_path):\n",
    "            os.makedirs(output_directory_path)\n",
    "        output_file_path = os.path.join(output_directory_path, f\"{os.path.splitext(file)[0]}_cleaned.csv\")\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "\n",
    "        summary.append(file_summary)\n",
    "\n",
    "    # 결과 요약 출력\n",
    "    print(\"\\n--- 처리 결과 요약 ---\\n\")\n",
    "    for s in summary:\n",
    "        print(f\"파일명: {s['file']}, 초기 행 수: {s['initial_rows']}, 최종 행 수: {s['final_rows']}, 제거된 결측치 수: {s['missing_removed']}\")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 결측치 확인 및 처리 수행",
   "id": "d98d02eafd8644e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T05:29:29.475953Z",
     "start_time": "2024-04-24T05:29:28.952039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_directory_path = 'powermetrics/'\n",
    "output_directory_path = 'cleaned_data/powermetrics/'\n",
    "load_and_clean_data(input_directory_path, output_directory_path)\n",
    "\n",
    "input_directory_path = 'environmentalsensors/'\n",
    "output_directory_path = 'cleaned_data/environmentalsensors/'\n",
    "load_and_clean_data(input_directory_path, output_directory_path)"
   ],
   "id": "d3c899eaea1d6e24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 처리 결과 요약 ---\n",
      "\n",
      "파일명: 04_21_powermetrics_data.csv, 초기 행 수: 19440, 최종 행 수: 19440, 제거된 결측치 수: 0\n",
      "파일명: 04_15_powermetrics_data.csv, 초기 행 수: 19440, 최종 행 수: 19440, 제거된 결측치 수: 0\n",
      "파일명: 04_16_powermetrics_data.csv, 초기 행 수: 19440, 최종 행 수: 19440, 제거된 결측치 수: 0\n",
      "파일명: 04_17_powermetrics_data.csv, 초기 행 수: 19440, 최종 행 수: 19440, 제거된 결측치 수: 0\n",
      "파일명: 04_20_powermetrics_data.csv, 초기 행 수: 19440, 최종 행 수: 19440, 제거된 결측치 수: 0\n",
      "파일명: 04_18_powermetrics_data.csv, 초기 행 수: 19197, 최종 행 수: 19197, 제거된 결측치 수: 0\n",
      "파일명: 04_23_powermetrics_data.csv, 초기 행 수: 19436, 최종 행 수: 19436, 제거된 결측치 수: 0\n",
      "파일명: 04_19_powermetrics_data.csv, 초기 행 수: 19440, 최종 행 수: 19440, 제거된 결측치 수: 0\n",
      "파일명: 04_22_powermetrics_data.csv, 초기 행 수: 19440, 최종 행 수: 19440, 제거된 결측치 수: 0\n",
      "\n",
      "--- 처리 결과 요약 ---\n",
      "\n",
      "파일명: 04_20_environmentalsensors_data.csv, 초기 행 수: 2853, 최종 행 수: 2853, 제거된 결측치 수: 0\n",
      "파일명: 04_18_environmentalsensors_data.csv, 초기 행 수: 2817, 최종 행 수: 2817, 제거된 결측치 수: 0\n",
      "파일명: 04_16_environmentalsensors_data.csv, 초기 행 수: 3316, 최종 행 수: 3316, 제거된 결측치 수: 0\n",
      "파일명: 04_17_environmentalsensors_data.csv, 초기 행 수: 2851, 최종 행 수: 2851, 제거된 결측치 수: 0\n",
      "파일명: 04_15_environmentalsensors_data.csv, 초기 행 수: 3573, 최종 행 수: 3573, 제거된 결측치 수: 0\n",
      "파일명: 04_22_environmentalsensors_data.csv, 초기 행 수: 2849, 최종 행 수: 2849, 제거된 결측치 수: 0\n",
      "파일명: 04_19_environmentalsensors_data.csv, 초기 행 수: 2853, 최종 행 수: 2853, 제거된 결측치 수: 0\n",
      "파일명: 04_21_environmentalsensors_data.csv, 초기 행 수: 2856, 최종 행 수: 2856, 제거된 결측치 수: 0\n",
      "파일명: 04_23_environmentalsensors_data.csv, 초기 행 수: 2846, 최종 행 수: 2846, 제거된 결측치 수: 0\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 각 데이터 병합 수행",
   "id": "ca053631c38ed7f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T05:37:54.942891Z",
     "start_time": "2024-04-24T05:37:54.244972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "powermetrics_path = 'cleaned_data/powermetrics'\n",
    "file_name = 'powermetrics_stats.csv'\n",
    "stats_values_df = merge_and_compute_stats_by_time_and_place(powermetrics_path, file_name)\n",
    "print(stats_values_df.head())\n",
    "\n",
    "environmentalsensors_path = 'cleaned_data/environmentalsensors'\n",
    "file_name = 'environmentalsensors_stats.csv'\n",
    "stats_values_df = merge_and_compute_stats_by_time_and_place(environmentalsensors_path, file_name)\n",
    "print(stats_values_df.head())"
   ],
   "id": "fd4ce04992e75141",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  time_hour_min    place                 location  min_value  max_value  \\\n",
      "0         00:00  class_a           ac_indoor_unit       22.5      166.5   \n",
      "1         00:00  class_a          ac_outdoor_unit       24.0     4748.0   \n",
      "2         00:00  class_a           automatic_door        7.0       14.0   \n",
      "3         00:00  class_a  outdoor_unit_room_light        0.0        0.0   \n",
      "4         00:00   office                a_project       24.5       28.0   \n",
      "\n",
      "   mean_value  median_value      std_dev  \n",
      "0   49.111111          24.0    46.553583  \n",
      "1  959.722222         150.0  1574.839181  \n",
      "2    9.277778           8.0     2.359967  \n",
      "3    0.000000           0.0     0.000000  \n",
      "4   25.833333          26.0     1.000000  \n",
      "  time_hour_min    place             location  min_value  max_value  \\\n",
      "0         00:00  class_a   bottom_left_corner       23.0      23.00   \n",
      "1         00:00  class_a  bottom_right_corner       21.6      23.40   \n",
      "2         00:00  class_a               indoor       23.0      24.50   \n",
      "3         00:00  class_a     top_right_corner       22.5      23.95   \n",
      "4         00:00   office               indoor       23.0      24.40   \n",
      "\n",
      "   mean_value  median_value   std_dev  \n",
      "0   23.000000         23.00  0.000000  \n",
      "1   22.722222         22.90  0.591138  \n",
      "2   23.766667         23.85  0.495606  \n",
      "3   23.294444         23.40  0.488905  \n",
      "4   23.744444         23.70  0.444722  \n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a470c8a493004f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> ### 전력, 온도 데이터의 연관 관계 측정",
   "id": "5bec7fffafe4915c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "전력과 온도 데이터를 가지고 연관관계를 측정 해볼 것이다. \n",
    "\n",
    "조건은 평균 전력 사용량과 평균 온도를 계산하며 두 데이터 프레임을 시간대 기준으로 결합을 할 것이다. 이후 상관관계에 대해서 수치를 나타내어 확인을 해볼 것이다."
   ],
   "id": "56f9f1840012584a"
  },
  {
   "cell_type": "code",
   "id": "06b104c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T05:29:50.873958Z",
     "start_time": "2024-04-24T05:29:50.833404Z"
    }
   },
   "source": [
    "# 전력 사용량 데이터와 환경 센서 데이터를 로드합니다.\n",
    "powermetrics_df = pd.read_csv('powermetrics_stats.csv')\n",
    "environmentalsensors_df = pd.read_csv('environmentalsensors_stats.csv')\n",
    "\n",
    "# 시간대별로 그룹화하여 각 시간대의 평균 전력 사용량을 계산합니다.\n",
    "power_avg = powermetrics_df.groupby('time_hour_min').mean_value.mean().reset_index(name='avg_power_usage')\n",
    "\n",
    "# 시간대별로 그룹화하여 각 시간대의 평균 온도를 계산합니다.\n",
    "temp_avg = environmentalsensors_df.groupby('time_hour_min').mean_value.mean().reset_index(name='avg_temperature')\n",
    "\n",
    "# 두 데이터프레임을 시간대(time_hour_min)를 기준으로 결합합니다.\n",
    "combined_data = pd.merge(power_avg, temp_avg, on='time_hour_min')\n",
    "\n",
    "# 상관관계 계산\n",
    "correlation = combined_data[['avg_power_usage', 'avg_temperature']].corr()\n",
    "\n",
    "# 상관관계 출력\n",
    "print(\"온도와 전력 사용량 사이의 상관계수는 :\", correlation)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "온도와 전력 사용량 사이의 상관계수는 :                  avg_power_usage  avg_temperature\n",
      "avg_power_usage         1.000000         0.892986\n",
      "avg_temperature         0.892986         1.000000\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
