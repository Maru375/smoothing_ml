{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84806715",
   "metadata": {},
   "source": "> # 공통 환경 처리"
  },
  {
   "cell_type": "code",
   "id": "b16400a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T02:03:13.063604Z",
     "start_time": "2024-04-25T02:03:10.841095Z"
    }
   },
   "source": [
    "%pip install influxdb_client"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb_client in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (1.42.0)\r\n",
      "Requirement already satisfied: reactivex>=4.0.4 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (4.0.4)\r\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (2.8.2)\r\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (68.0.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (1.26.16)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.5.3->influxdb_client) (1.16.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from reactivex>=4.0.4->influxdb_client) (4.7.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "46e54772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T02:03:13.427209Z",
     "start_time": "2024-04-25T02:03:13.068372Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from influxdb_client import InfluxDBClient\n",
    "from datetime import datetime, timedelta"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Influx DB 접속 정보 및 장치 위치 맵핑 정보",
   "id": "c6c3a3b4f5ea98a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T02:03:13.431427Z",
     "start_time": "2024-04-25T02:03:13.428314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# InfluxDB 설정 정보\n",
    "url = \"http://133.186.144.22:8086\"\n",
    "token = \"BPJ1pnKvoaov4Tte971t0zpRSTUXNZvrshU7u3UPheAIsBeUJEFfbKjfsZjtwZmugkHJEGRW17lH4bR9ybanNQ==\"\n",
    "org = \"smoothing\"\n",
    "\n",
    "# 디바이스 ID와 위치를 매핑\n",
    "location_mapping = {\n",
    "    '24e124126d152919': 'indoor',\n",
    "    '24e124126d152969': 'bottom_right_corner',\n",
    "    '24e124128c067999': 'indoor',\n",
    "    '24e124785c389818': 'bottom_left_corner',\n",
    "    '24e124785c421885': 'top_right_corner'\n",
    "}"
   ],
   "id": "f7fb2f9922864375",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "7f08064d",
   "metadata": {},
   "source": "> # 데이터 집계 함수"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "influx DB에서 데이터를 받아와 Time, Value, Place, Location, Device 컬럼 형태로 지정을 하였다.\n",
    "\n",
    "또한 전력 데이터와 온도 데이터를 받을 예정이다."
   ],
   "id": "16c89731a4b83f08"
  },
  {
   "cell_type": "code",
   "id": "83c508c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T02:03:13.440692Z",
     "start_time": "2024-04-25T02:03:13.433291Z"
    }
   },
   "source": [
    "# InfluxDB 클라이언트 생성\n",
    "def create_client(url, token, org):\n",
    "    return InfluxDBClient(url=url, token=token, org=org)\n",
    "\n",
    "# 쿼리 실행 및 DataFrame으로 변환\n",
    "def query_to_dataframe(client, query):\n",
    "    result = client.query_api().query(query=query)\n",
    "    results = []\n",
    "    \n",
    "    for table in result:\n",
    "        for record in table.records:\n",
    "            results.append({\n",
    "                \"time\": record.get_time(),\n",
    "                \"value\": record.get_value(),\n",
    "                \"place\": record.values.get(\"place\"),\n",
    "                \"location\": record.values.get(\"location\"),\n",
    "                \"device\": record.values.get(\"device\")\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['time'] = df['time'].astype(str).str.replace(r'\\+00:00$', '', regex=True)\n",
    "    return df\n",
    "\n",
    "# 데이터를 날짜를 지정하여 CSV 파일로 저장\n",
    "def save_csv(df, file_pattern, directory):\n",
    "    # 경로가 존재하는지 확인하고, 없다면 생성\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    current_date = datetime.now()\n",
    "    previous_date = current_date - timedelta(days=1)\n",
    "    filename = f\"{directory}{previous_date.strftime(file_pattern)}\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "# 온도 Data에서 'device' 열에 따라 'location' 열을 업데이트    \n",
    "def update_location(df, location_mapping):\n",
    "    df['location'] = df['device'].map(location_mapping)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "c90e48ee",
   "metadata": {},
   "source": "### 각 데이터 조회 및 CSV변환 수행"
  },
  {
   "cell_type": "code",
   "id": "de06b4e8",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:03:14.693850Z",
     "start_time": "2024-04-25T02:03:13.441913Z"
    }
   },
   "source": [
    "# 클라이언트 생성 및 쿼리 실행\n",
    "client = create_client(url, token, org)\n",
    "\n",
    "# 전력 조회 Flux 쿼리\n",
    "query_powermetrics = '''\n",
    "import \"date\"\n",
    "\n",
    "from(bucket: \"powermetrics_data\")\n",
    "  |> range(start: date.sub(d: 1d, from: date.truncate(t: now(), unit: 1d)), stop: date.truncate(t: now(), unit: 1d))\n",
    "  |> filter(fn: (r) => r[\"phase\"] == \"total\")\n",
    "  |> filter(fn: (r) => r[\"description\"] == \"w\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\" or r[\"place\"] == \"office\")\n",
    "  |> filter(fn: (r) => r[\"location\"] != \"main\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# CSV 변환\n",
    "df_powermetrics = query_to_dataframe(client, query_powermetrics)\n",
    "print(df_powermetrics.head())\n",
    "save_csv(df_powermetrics, \"%m_%d_powermetrics_data.csv\", \"powermetrics/\")\n",
    "\n",
    "\n",
    "# 온도 조회 Flux 쿼리\n",
    "query_environmental = '''\n",
    "import \"date\"\n",
    "from(bucket: \"environmentalsensors_data\")\n",
    "  |> range(start: date.sub(d: 1d, from: date.truncate(t: now(), unit: 1d)), stop: date.truncate(t: now(), unit: 1d))\n",
    "  |> filter(fn: (r) => r[\"measurement\"] == \"temperature\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\" or r[\"place\"] == \"office\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# CSV 변환\n",
    "df_environmental = query_to_dataframe(client, query_environmental)\n",
    "df_environmental_fix = update_location(df_environmental, location_mapping)\n",
    "print(df_environmental_fix.head())\n",
    "save_csv(df_environmental_fix, \"%m_%d_environmentalsensors_data.csv\", \"environmentalsensors/\")\n",
    "\n",
    "# 클라이언트 종료\n",
    "client.close()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time  value   place   location     device\n",
      "0  2024-04-24 00:02:00   29.5  office  a_project  gems-3500\n",
      "1  2024-04-24 00:04:00   29.5  office  a_project  gems-3500\n",
      "2  2024-04-24 00:06:00  137.5  office  a_project  gems-3500\n",
      "3  2024-04-24 00:08:00  124.5  office  a_project  gems-3500\n",
      "4  2024-04-24 00:10:00  121.0  office  a_project  gems-3500\n",
      "                  time  value   place location            device\n",
      "0  2024-04-24 00:02:00   23.8  office   indoor  24e124126d152919\n",
      "1  2024-04-24 00:06:00   23.8  office   indoor  24e124126d152919\n",
      "2  2024-04-24 00:08:00   23.8  office   indoor  24e124126d152919\n",
      "3  2024-04-24 00:10:00   23.9  office   indoor  24e124126d152919\n",
      "4  2024-04-24 00:12:00   23.8  office   indoor  24e124126d152919\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> # 데이터 전처리",
   "id": "8cb9999c8f3aa739"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "데이터 전처리를 위해 결측치 제거와 이상치 제거를 할 것이다.\n",
    "\n",
    "온도데이터와, 전력데이터 빈값이 있을 수 있으므로 결측치를 제거한다.\n",
    "\n",
    "이상치는 어떠한 것을 위해 제거한다."
   ],
   "id": "ef66dd972c0c777f"
  },
  {
   "cell_type": "markdown",
   "id": "acfcf9407e5143bc",
   "metadata": {},
   "source": "### 전체 데이터 병합 및 결측치 처리 함수"
  },
  {
   "cell_type": "code",
   "id": "b7f609080cfb5ae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:47:45.658071Z",
     "start_time": "2024-04-25T06:47:45.649018Z"
    }
   },
   "source": [
    "# 전체 데이터 병합\n",
    "def merge_data(directory_path, file_name):\n",
    "    # 디렉토리 내의 모든 CSV 파일 목록을 생성\n",
    "    csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "    # 모든 CSV 파일을 데이터 프레임으로 읽어와 하나로 병합\n",
    "    data_frames = []\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        data_frames.append(df)\n",
    "\n",
    "    # 모든 데이터 프레임을 하나로 병합\n",
    "    merged_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # 원하는 컬럼만 선택\n",
    "    columns_to_keep = ['time', 'value', 'place', 'location']\n",
    "    filtered_df = merged_df[columns_to_keep]\n",
    "\n",
    "    # 'place', 'time'으로 정렬\n",
    "    sorted_df = filtered_df.sort_values(['place', 'time'])\n",
    "\n",
    "    # 결과 데이터 프레임을 CSV 파일로 저장\n",
    "    sorted_df.to_csv(file_name, index=False)\n",
    "\n",
    "    return sorted_df\n",
    "\n",
    "# 결측치 확인 및 처리\n",
    "def load_and_clean_data(df, output_directory_path, file_name):\n",
    "    # 요약 사전 초기화\n",
    "    file_summary = {}\n",
    "\n",
    "    # 데이터프레임의 초기 형태 저장\n",
    "    initial_shape = df.shape\n",
    "\n",
    "    # 정리 전 총 결측치 수 계산\n",
    "    missing_before = df.isnull().sum().sum()\n",
    "\n",
    "    # 결측치 제거\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # 정리 후 결측치가 제거되었는지 확인하기 위해 결측치 수 다시 계산\n",
    "    missing_after = df.isnull().sum().sum()\n",
    "\n",
    "    # 요약 사전 업데이트\n",
    "    file_summary[\"file\"] = file_name\n",
    "    file_summary[\"initial_rows\"] = initial_shape[0]\n",
    "    file_summary[\"final_rows\"] = df.shape[0]\n",
    "    file_summary[\"missing_removed\"] = missing_before - missing_after\n",
    "\n",
    "    # 출력 디렉토리가 존재하지 않는 경우 생성\n",
    "    if not os.path.exists(output_directory_path):\n",
    "        os.makedirs(output_directory_path)\n",
    "\n",
    "    # 출력 파일 경로 구성\n",
    "    output_file_path = os.path.join(output_directory_path, f\"{file_name}_cleaned.csv\")\n",
    "\n",
    "    # 정리된 데이터프레임을 CSV로 저장\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    # 처리 결과 요약 출력\n",
    "    print(\"\\n--- 처리 결과 요약 ---\\n\")\n",
    "    print(f\"파일 이름: {file_summary['file']}, 초기 행 수: {file_summary['initial_rows']}, 최종 행 수: {file_summary['final_rows']}, 제거된 결측치 수: {file_summary['missing_removed']}\")\n",
    "    print(\"\")"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 각 데이터 병합 수행 및 결측치 처리",
   "id": "ca053631c38ed7f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:47:48.525027Z",
     "start_time": "2024-04-25T06:47:47.608233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "powermetrics_path = 'powermetrics'\n",
    "file_name = 'powermetrics_stats.csv'\n",
    "stats_values_df = merge_data(powermetrics_path, file_name)\n",
    "print(stats_values_df.head())\n",
    "load_and_clean_data(stats_values_df, \"cleaned_data/powermetrics/\", \"powermetrics_stats\")\n",
    "\n",
    "environmentalsensors_path = 'environmentalsensors'\n",
    "file_name = 'environmentalsensors_stats.csv'\n",
    "stats_values_df = merge_data(environmentalsensors_path, file_name)\n",
    "print(stats_values_df.head())\n",
    "load_and_clean_data(stats_values_df, \"cleaned_data/environmentalsensors/\", \"environmentalsensors_stats\")"
   ],
   "id": "fd4ce04992e75141",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     time  value    place                 location\n",
      "20880 2024-04-15 00:02:00   23.5  class_a           ac_indoor_unit\n",
      "22320 2024-04-15 00:02:00  112.5  class_a          ac_outdoor_unit\n",
      "24480 2024-04-15 00:02:00    8.0  class_a           automatic_door\n",
      "33840 2024-04-15 00:02:00    0.0  class_a  outdoor_unit_room_light\n",
      "20881 2024-04-15 00:04:00   23.5  class_a           ac_indoor_unit\n",
      "\n",
      "--- 처리 결과 요약 ---\n",
      "\n",
      "파일 이름: powermetrics_stats, 초기 행 수: 194153, 최종 행 수: 194153, 제거된 결측치 수: 0\n",
      "\n",
      "                     time  value    place             location\n",
      "12544 2024-04-15 00:02:00  23.10  class_a  bottom_right_corner\n",
      "13250 2024-04-15 00:02:00  23.85  class_a               indoor\n",
      "13970 2024-04-15 00:02:00  23.50  class_a   bottom_left_corner\n",
      "14690 2024-04-15 00:02:00  23.40  class_a     top_right_corner\n",
      "12545 2024-04-15 00:04:00  23.20  class_a  bottom_right_corner\n",
      "\n",
      "--- 처리 결과 요약 ---\n",
      "\n",
      "파일 이름: environmentalsensors_stats, 초기 행 수: 29668, 최종 행 수: 29668, 제거된 결측치 수: 0\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> ### 전력, 온도 데이터의 연관 관계 측정",
   "id": "5bec7fffafe4915c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "전력과 온도 데이터를 가지고 연관관계를 측정 해볼 것이다. \n",
    "\n",
    "조건은 평균 전력 사용량과 평균 온도를 계산하며 두 데이터 프레임을 시간대 기준으로 결합을 할 것이다. 이후 상관관계에 대해서 수치를 나타내어 확인을 해볼 것이다."
   ],
   "id": "56f9f1840012584a"
  },
  {
   "cell_type": "code",
   "id": "06b104c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:52:44.367910Z",
     "start_time": "2024-04-25T06:52:44.228371Z"
    }
   },
   "source": [
    "# 전력 사용량 데이터와 환경 센서 데이터를 로드합니다.\n",
    "environmentalsensors_df = pd.read_csv('cleaned_data/environmentalsensors/environmentalsensors_stats_cleaned.csv')\n",
    "powermetrics_df = pd.read_csv('cleaned_data/powermetrics/powermetrics_stats_cleaned.csv')\n",
    "\n",
    "# 시간대별로 그룹화하여 각 시간대의 평균 전력 사용량을 계산합니다.\n",
    "power_avg = powermetrics_df.groupby('time').value.mean().reset_index(name='avg_power_usage')\n",
    "\n",
    "# 시간대별로 그룹화하여 각 시간대의 평균 온도를 계산합니다.\n",
    "temp_avg = environmentalsensors_df.groupby('time').value.mean().reset_index(name='avg_temperature')\n",
    "\n",
    "# 두 데이터프레임을 시간대(time_hour_min)를 기준으로 결합합니다.\n",
    "combined_data = pd.merge(power_avg, temp_avg, on='time')\n",
    "\n",
    "# 상관관계 계산\n",
    "correlation = combined_data[['avg_power_usage', 'avg_temperature']].corr()\n",
    "\n",
    "# 상관관계 출력\n",
    "print(\"온도와 전력 사용량 사이의 상관계수는 :\", correlation)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "온도와 전력 사용량 사이의 상관계수는 :                  avg_power_usage  avg_temperature\n",
      "avg_power_usage         1.000000         0.503633\n",
      "avg_temperature         0.503633         1.000000\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:57:05.287237Z",
     "start_time": "2024-04-25T06:57:05.131375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# 전력 사용 데이터와 환경 센서 데이터 로드하기.\n",
    "environmentalsensors_df = pd.read_csv('cleaned_data/environmentalsensors/environmentalsensors_stats_cleaned.csv')\n",
    "powermetrics_df = pd.read_csv('cleaned_data/powermetrics/powermetrics_stats_cleaned.csv')\n",
    "\n",
    "# 이상치 제거 함수 (z-score 사용)\n",
    "def remove_outliers_by_zscore(df, column_name, z_thresh=2.1):\n",
    "    # 열의 z-score 계산\n",
    "    df['z_score'] = zscore(df[column_name])\n",
    "    # z-score가 임계값 이내인 데이터만 필터링\n",
    "    return df[df['z_score'].abs() <= z_thresh].drop(columns=['z_score'])\n",
    "\n",
    "# 각 데이터 세트에 z-score 이상치 제거 적용\n",
    "powermetrics_df = remove_outliers_by_zscore(powermetrics_df, 'value')\n",
    "environmentalsensors_df = remove_outliers_by_zscore(environmentalsensors_df, 'value')\n",
    "\n",
    "# 시간 기간별로 그룹화하고 각 시간 기간에 대한 평균 전력 사용량 계산\n",
    "power_avg = powermetrics_df.groupby('time').value.mean().reset_index(name='avg_power_usage')\n",
    "\n",
    "# 시간 기간별로 그룹화하고 각 시간 기간에 대한 평균 온도 계산\n",
    "temp_avg = environmentalsensors_df.groupby('time').value.mean().reset_index(name='avg_temperature')\n",
    "\n",
    "# 시간대(time_hour_min)를 기준으로 두 데이터 프레임 결합\n",
    "combined_data = pd.merge(power_avg, temp_avg, on='time')\n",
    "\n",
    "# 상관 관계 계산\n",
    "correlation = combined_data[['avg_power_usage', 'avg_temperature']].corr()\n",
    "\n",
    "# 상관계수 출력\n",
    "print(\"온도와 전력 사용 사이의 상관계수는 다음과 같습니다:\")\n",
    "print(correlation)"
   ],
   "id": "b7c4bb7cea510e45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "온도와 전력 사용 사이의 상관계수는 다음과 같습니다:\n",
      "                 avg_power_usage  avg_temperature\n",
      "avg_power_usage         1.000000         0.603014\n",
      "avg_temperature         0.603014         1.000000\n"
     ]
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
