{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899284166d0cc91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T09:52:18.903784Z",
     "start_time": "2024-04-23T09:52:16.916199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb_client in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (1.42.0)\r\n",
      "Requirement already satisfied: reactivex>=4.0.4 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (4.0.4)\r\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (2.8.2)\r\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (68.0.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (1.26.16)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.5.3->influxdb_client) (1.16.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from reactivex>=4.0.4->influxdb_client) (4.7.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install influxdb_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9063ec07cd2ed7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T09:52:30.668945Z",
     "start_time": "2024-04-23T09:52:30.601566Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from influxdb_client import InfluxDBClient\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 디바이스 ID와 위치를 매핑\n",
    "location_mapping = {\n",
    "    '24e124126d152919': 'indoor',\n",
    "    '24e124126d152969': 'bottom_right_corner',\n",
    "    '24e124128c067999': 'indoor',\n",
    "    '24e124785c389818': 'bottom_left_corner',\n",
    "    '24e124785c421885': 'top_right_corner'\n",
    "}\n",
    "\n",
    "# InfluxDB 설정 정보\n",
    "url = \"http://133.186.144.22:8086\"\n",
    "token = \"BPJ1pnKvoaov4Tte971t0zpRSTUXNZvrshU7u3UPheAIsBeUJEFfbKjfsZjtwZmugkHJEGRW17lH4bR9ybanNQ==\"\n",
    "org = \"smoothing\"\n",
    "\n",
    "# 디바이스 ID와 위치를 매핑\n",
    "location_mapping = {\n",
    "    '24e124126d152919': 'indoor',\n",
    "    '24e124126d152969': 'bottom_right_corner',\n",
    "    '24e124128c067999': 'indoor',\n",
    "    '24e124785c389818': 'bottom_left_corner',\n",
    "    '24e124785c421885': 'top_right_corner'\n",
    "}\n",
    "\n",
    "# InfluxDB 클라이언트 생성\n",
    "def create_client(url, token, org):\n",
    "    return InfluxDBClient(url=url, token=token, org=org)\n",
    "\n",
    "# 쿼리 실행 및 DataFrame으로 변환\n",
    "def query_to_dataframe(client, query):\n",
    "    result = client.query_api().query(query=query)\n",
    "    results = []\n",
    "    \n",
    "    for table in result:\n",
    "        for record in table.records:\n",
    "            results.append({\n",
    "                \"time\": record.get_time(),\n",
    "                \"value\": record.get_value(),\n",
    "                \"place\": record.values.get(\"place\"),\n",
    "                \"location\": record.values.get(\"location\"),\n",
    "                \"device\": record.values.get(\"device\")\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['time'] = df['time'].astype(str).str.replace(r'\\+00:00$', '', regex=True)\n",
    "    return df\n",
    "\n",
    "# 데이터를 날짜를 지정하여 CSV 파일로 저장\n",
    "def save_csv(df, file_pattern, directory):\n",
    "    # 경로가 존재하는지 확인하고, 없다면 생성\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    current_date = datetime.now()\n",
    "    previous_date = current_date - timedelta(days=1)\n",
    "    filename = f\"{directory}{previous_date.strftime(file_pattern)}\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "# 온도 Data에서 'device' 열에 따라 'location' 열을 업데이트    \n",
    "def update_location(df, location_mapping):\n",
    "    df['location'] = df['device'].map(location_mapping)\n",
    "    return df\n",
    "\n",
    "# 결측치 확인 및 처리\n",
    "def load_and_clean_data(file_path):\n",
    "    print(\"\\n--- 데이터 처리 시작 ---\\n\")\n",
    "    # 데이터 불러오기\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 파일명 출력\n",
    "    print(f\"파일명: {file_path.split('/')[-1]}\")\n",
    "\n",
    "    # 결측치 확인\n",
    "    print(\"결측치 수:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # 결측치 제거 전의 데이터 크기 출력\n",
    "    print(f\"결측치 제거 전의 데이터 크기 : {df.shape}\")\n",
    "\n",
    "    # 결측치 제거\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # 결측치 제거 후의 데이터 크기 출력\n",
    "    print(f\"결측치 제거 후의 데이터 크기 : {df.shape}\")\n",
    "\n",
    "    print(\"\\n--- 데이터 처리 완료 ---\\n\")\n",
    "    return df\n",
    "\n",
    "# 처리한 DF를 다른 폴더에 저장\n",
    "def process_csv_files(folder_path, output_folder):\n",
    "    summary = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = load_and_clean_data(file_path)\n",
    "\n",
    "            # 저장할 파일의 경로 설정\n",
    "            output_file_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # CSV 파일로 저장\n",
    "            df.to_csv(output_file_path, index=False)\n",
    "            print(f\"저장 완료: {output_file_path}\")\n",
    "            \n",
    "            summary.append({\n",
    "                'filename': filename,\n",
    "                'original_rows': df.shape[0] + df.isnull().any().sum(),\n",
    "                'rows_after_cleaning': df.shape[0]\n",
    "            })\n",
    "\n",
    "    # 결과 요약 정보 출력\n",
    "    for info in summary:\n",
    "        print(f\"{info['filename']}: 원래 행 수 = {info['original_rows']}, 정리 후 행 수 = {info['rows_after_cleaning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77d40ce74c9c09",
   "metadata": {},
   "source": [
    "### 쿼리 사용하여 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aca21c3030b4b504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T09:57:17.310501Z",
     "start_time": "2024-04-23T09:57:16.167434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time  value   place   location     device\n",
      "0  2024-04-22 00:02:00   25.0  office  a_project  gems-3500\n",
      "1  2024-04-22 00:04:00   25.0  office  a_project  gems-3500\n",
      "2  2024-04-22 00:06:00   26.0  office  a_project  gems-3500\n",
      "3  2024-04-22 00:08:00   26.0  office  a_project  gems-3500\n",
      "4  2024-04-22 00:10:00   26.0  office  a_project  gems-3500\n",
      "                  time  value   place location            device\n",
      "0  2024-04-22 00:02:00   23.3  office   indoor  24e124126d152919\n",
      "1  2024-04-22 00:04:00   23.3  office   indoor  24e124126d152919\n",
      "2  2024-04-22 00:06:00   23.4  office   indoor  24e124126d152919\n",
      "3  2024-04-22 00:08:00   23.4  office   indoor  24e124126d152919\n",
      "4  2024-04-22 00:10:00   23.4  office   indoor  24e124126d152919\n"
     ]
    }
   ],
   "source": [
    "# 클라이언트 생성 및 쿼리 실행\n",
    "client = create_client(url, token, org)\n",
    "\n",
    "# 전력 조회 Flux 쿼리\n",
    "query_powermetrics = '''\n",
    "import \"date\"\n",
    "\n",
    "from(bucket: \"powermetrics_data\")\n",
    "  |> range(start: 2024-04-22T00:00:00Z, stop: 2024-04-23T00:00:00Z)\n",
    "  |> filter(fn: (r) => r[\"phase\"] == \"total\")\n",
    "  |> filter(fn: (r) => r[\"description\"] == \"w\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\" or r[\"place\"] == \"office\")\n",
    "  |> filter(fn: (r) => r[\"location\"] != \"main\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# CSV 변환\n",
    "df_powermetrics = query_to_dataframe(client, query_powermetrics)\n",
    "print(df_powermetrics.head())\n",
    "save_csv(df_powermetrics, \"04_22_powermetrics_data.csv\", \"update_location/power/\")\n",
    "\n",
    "# 온도 조회 Flux 쿼리\n",
    "query_environmental = '''\n",
    "import \"date\"\n",
    "from(bucket: \"environmentalsensors_data\")\n",
    "  |> range(start: 2024-04-22T00:00:00Z, stop: 2024-04-23T00:00:00Z)\n",
    "  |> filter(fn: (r) => r[\"measurement\"] == \"temperature\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\" or r[\"place\"] == \"office\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# CSV 변환\n",
    "df_environmental = query_to_dataframe(client, query_environmental)\n",
    "df_environmental_fix = update_location(df_environmental, location_mapping)\n",
    "print(df_environmental_fix.head())\n",
    "save_csv(df_environmental_fix, \"04_22_environmentalsensors_data.csv\", \"update_location/temp/\")\n",
    "\n",
    "# 클라이언트 종료\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07443030",
   "metadata": {},
   "source": [
    "### 기존 파일 location 업데이트 (구 버전으로 생성된 파일들에 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8153ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T01:21:31.228378Z",
     "start_time": "2024-04-22T01:21:31.221750Z"
    }
   },
   "outputs": [],
   "source": [
    "# 온도 Data에서 'device' 열에 따라 'location' 열을 업데이트    \n",
    "def update_location(df, location_mapping):\n",
    "    df['location'] = df['device'].map(location_mapping)\n",
    "    return df\n",
    "\n",
    "def process_files(fix_directory, directory, location_mapping):\n",
    "    # 폴더 내의 모든 파일을 리스트업\n",
    "    for filename in os.listdir(fix_directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(fix_directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            updated_df = update_location(df, location_mapping)\n",
    "            \n",
    "            # 새 파일 경로 생성\n",
    "            new_file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            # 업데이트된 DataFrame을 새 경로에 저장\n",
    "            updated_df.to_csv(new_file_path, index=False)\n",
    "            print(f\"Processed and saved: {new_file_path}\")\n",
    "\n",
    "# 수정할 파일 경로\n",
    "fix_directory = 'update_location/'\n",
    "\n",
    "# 저장할 파일 경로\n",
    "directory = 'environmentalsensors/'\n",
    "\n",
    "# 파일 처리 실행\n",
    "process_files(fix_directory, directory, location_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoothing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
